Source code for the paper: [Gunchen Sun, et al., "SpikeNAS-Bench: Benchmarking NAS Algorithms for Spiking Neural Network Architecture", IEEE Transactions on Artificial Intelligence (2024).](https://ieeexplore.ieee.org/abstract/document/10855683)

# User Guide of the SpikeNAS_Bench Demo

SpikeNAS_Bench provides the training results of all neural networks within the search space. To demonstrate its effectiveness, a demo is provided here to show how to use the NAS algorithm to search for the optimal network architecture.

There are three folders here, and the contents of each folder are introduced below:

```
SpikeNAS_Bench_Demo/
    ├── data/
        ├── CIFAR10/
        ├── CIFAR100/
        ├── TinyImagenet/
        └── data_readme.txt
    ├── NAS/
        ├── foresight/
        ├── search_result/
        ├── searchcells/
        ├── config.py
        ├── evaluator.py
        ├── evolution_algorithm.py
        ├── get_train_log.py
        ├── main.py
        ├── model_snn_withoutcupy.py
        └── utils.py
    ├── Train_all_networks/
        ├── dataset/
        ├── searchcells/
        ├── config.py
        ├── model_snn.py
        ├── train_all_networks.py
        └── utils.py
```

## data folder

This folder contains training data for 15625 networks trained on different datasets. The data in the CIFAR10 folder is complete and serves as the data foundation for the NAS search below. Only a portion of the data is displayed in the CIFAR100 and Tiny Imagenet folders to reduce memory usage.

## NAS folder

This folder contains the code for using genetic algorithm to search NAS, which uses genetic algorithm to find the network with the highest accuracy.We suggest that you run this code to view the NAS search results.

## Train_all_networks folder

This folder contains the code for training 15625 networks using the cifar10, cifar100, and Tiny Imagenet datasets. Each trained network will generate a txt file that stores the parameters and results of the network during operation. This code will consume a lot of time and is not recommended for you to run. We have placed some of the results generated by running this code in the data folder.



# User guide of the NAS search algorithm

Using NAS algorithm to find the optimal network structure.

### Hardware requirements

SpikeNAS_Bench requires a standard windows computer and some common hardware configurations. A GPU is not required, but it will greatly speed up the search if you have one.

### OS Requirements
This toolbox is supported for Windows. The toolbox has been tested on the following systems:
Windows 11 professional: 21H2

### Python Dependencies
SpikeNAS-Bench mainly depends on the following Python scientific stack:
- python
- pytorch
- torchvision
- spikingjelly
- numpy
- einops

## Installation Guide

### Install Anaconda

Anaconda is an open source tool that contains more than 180 science packages and their dependencies, including Conda, Python, numpy and scipy.

Anaconda version is Anaconda3-4.2.0-Windows-x86_64. You can find the version you want on the anaconda official website: `https://www.anaconda.com/download/`. It will probably take about 7 minutes to set up.

### Install Pycharm

PyCharm is a Python IDE with a full set of tools to help users to improve their productivity while developing in the Python language, such as debugging, syntax highlighting, Project management, code skipping, smart tips, auto-completion, unit testing, and version control.

The pycharm version is pycharm-community-2018.1. The community version is open source and can be downloaded from the website: `https://www.jetbrains.com/pycharm/download/#section=windows`. It will take about 5 minutes to set up.

### Install spikingjelly

SpikingJelly is a PyTorch-based framework for deep learning using Spiking Network (SNN).

On Windows system, open the command prompt and input:
```pip install spikingjelly```
Wait about 5 minutes for installation to complete.

### Install einops

Einops provides flexible and powerful tensor operations, ensuring code readability and reliability.

On Windows system, open the command prompt and input:
```pip install einops```
Wait about 1 minutes for installation to complete.

### Setting up the development environment

Click the PyCharm icon to run the software and create a new project. Then, the environment of the project is configured, and the configuration path is `File--Setting--Project--Project Interpreter--Set--Add--System Interpreter`, and finally select the path where the Anaconda installed.

If you configure the PyCharm environment for the first time, it will take about 10 minutes to initialize the Python environment.

## Run the demo

Run `main.py` file directly to search the best network architecture on the CIFAR10 dataset. You will see the running log like:
```
> python main.py
Namespace(exp_name='NAS', save_dir='./search_result', dataset='cifar10', seed=640, device='cuda:0', timestep=5, batch_size=256, epochs=64, tau=1.3333333333333333, threshold_low=0.5, threshold_middle=1.0, threshold_high=1.5, celltype='forward', second_avgpooling=2, heads=6, depth=4, dim=80, population_size=10, generation_number=10, fitness_evaluator='early_stop_40', pc=0.9, pm=0.2)
INFO:root:exp_name.................................................NAS
INFO:root:save_dir....................................../search_result
INFO:root:dataset..............................................cifar10
INFO:root:seed.....................................................640
INFO:root:device................................................cuda:0
INFO:root:timestep...................................................5
INFO:root:batch_size...............................................256
INFO:root:epochs....................................................64
INFO:root:tau.......................................1.3333333333333333
INFO:root:threshold_low............................................0.5
INFO:root:threshold_middle.........................................1.0
INFO:root:threshold_high...........................................1.5
INFO:root:celltype.............................................forward
INFO:root:second_avgpooling..........................................2
INFO:root:heads......................................................6
INFO:root:depth......................................................4
INFO:root:dim.......................................................80
INFO:root:population_size...........................................10
INFO:root:generation_number.........................................10
INFO:root:fitness_evaluator..............................early_stop_40
INFO:root:pc.......................................................0.9
INFO:root:pm.......................................................0.2
0
1
2
3
4
5
6
7
8
9
INFO:root:[architecture_14862] [params = 21607908] [val_acc = 88.640] [test_acc = 88.500]
INFO:root:total search time seconds: 878780.156594038
INFO:root:total search time: 244.0h 6.0m 20.156594038009644s
INFO:root:search time with SNAS: 0.15659403800964355s
```



The text `INFO:root:[architecture_14862] [params = 21607908] [val_acc = 88.640] [test_acc = 88.500]` indicates that the network number with the highest accuracy found in the search is `14862`, with parameters of `21607908`, validation accuracy of `88.640`, and testing accuracy of `88.500`.

In this demo, we provide three search strategies, `early_stop_10`, `early_stop_40` and `early_stop_60`。 Different search strategies can be adjusted by modifying the -- fitness_evaluator in line 28 of the config. py file.
